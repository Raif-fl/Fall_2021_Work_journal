{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b1a7d4-8ede-4530-8784-598021ff19b7",
   "metadata": {},
   "source": [
    "## Loading up packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceab2473-7d5f-44ca-9727-b10ab5a27f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plastid\n",
    "# data structure for mapping read alignments to genomic positions\n",
    "from plastid import BAMGenomeArray, VariableFivePrimeMapFactory, \\\n",
    "                        GTF2_TranscriptAssembler, Transcript, ThreePrimeMapFactory\n",
    "import numpy as np\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import csv\n",
    "from scipy.sparse.linalg import lsqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1e784bd-8656-4bd0-9be6-27ef04ece771",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/Users/keeganflanagan/Desktop/Khanh_position/Eggtart/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32bb390-4d54-4827-8361-e4af46cf4b5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# The Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7a2676-c346-4ed4-b97f-69775f2db79a",
   "metadata": {},
   "source": [
    "Wait wait wait, why is this all in codons? I had this set up on a per nucleotide position basis but now it is asking for this on a per codon basis. I guess it does not really matter for this first test but this is something I need to ask Khanh about. \n",
    "\n",
    "Ok, so first I am going to take each position in my table and divide that position by the total number of transcripts... when he says transcripts does he really mean reads? It makes no sense to just use whatever number of transcripts happen to be in the genome, it would be much more sensical to use the sum of all of the reads for a transcript. \n",
    "\n",
    "Perhaps step 2 is just referring to calculating the average p per 10 codons? So, add up all 10 p values, then divide by 1/10. when he says it should add up to n-9, does that imply that we are finding the average for codons 1-10, then 2-11, then 3-12 all the way up until we can no longer take the average of 10 codons? \n",
    "\n",
    "Then, for each set of 10 codons (x entry) calculate the smoothed elongation rate using a pretty straight forward equation. \n",
    "\n",
    "Then calculate the scaled initiation rate and termination rate using fairly simple equations and the pbar values calculated for the first and last set of codons. \n",
    "\n",
    "Then, you create an array of size n-8-L (n is the length of the gene in codons and L is related to bias and will be set as 1 for now) which contains 10* lambda(x) (the smoother elongation rate for the entries) for which x is between L and n-9. \n",
    "\n",
    "Can someone please explain to me what n is in this context? like n is usually the number of something but I cannot figure out which number in this context. Is it always equal to the gene length in codons? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3964f9cb-c183-4a98-ab01-37334ceeade8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading up the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5837a43c-99f0-4fe2-9727-4c805131f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(\"toy_data.csv\", newline = '') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8acb5dbd-396b-4d6e-888b-48998f6dc6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "blank=data.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40668469-516e-4544-8de2-2f1913e1fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,ii in zip(data, range(len(data))):\n",
    "    for j,jj in zip(i, range(len(i))):\n",
    "        try:\n",
    "            x = int(j)\n",
    "            data[ii][jj] = x\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f798c4ba-25a8-4c14-a0d5-ada794ffd463",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,ii in zip(data, range(len(data))):\n",
    "    x = list(filter(('').__ne__, i))\n",
    "    data[ii] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8379e568-7689-4314-82c9-63c480c67525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i,ii in zip(data, range(len(data))):\n",
    "    data[ii] = np.array(data[ii][2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfad7b5-b80b-4b95-b24e-a4d36ebd44b0",
   "metadata": {},
   "source": [
    "## Perform the calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c751070-c12f-4445-a93a-72a22cc9065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to obtain a normalized profile (p) of ribosome footprints.\n",
    "def calculate_p(data):\n",
    "    p_list=[]\n",
    "    for i in data:\n",
    "        M = sum(i)\n",
    "        p = i/M\n",
    "        p_list.append(p)\n",
    "    return(p_list)\n",
    "\n",
    "# Note that I am assuming here that by number of transcripts they meant number of reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "258b7055-d8b0-4e6a-bbb7-4b4c12070b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list = calculate_p(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17231693-a385-4ea1-9f76-20a8cf48f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the smoothed density vector pbar for xth entry with length n-9\n",
    "def calculate_pbar(p_list):\n",
    "    pbar_list=[]\n",
    "    for p in p_list:\n",
    "        x=0\n",
    "        pbar=[]\n",
    "        for px in p:\n",
    "            pbar_x = 0.1*sum(p[x:x+10]) #it is x+10 not x+9 because python does not include the final index.\n",
    "            pbar.append(pbar_x)\n",
    "            x = x+1\n",
    "            if x  == len(p)-9:\n",
    "                break\n",
    "        pbar_list.append(np.array(pbar))\n",
    "    return(pbar_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f382947-dd33-45fa-9ad2-0ded3d095c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar_list=calculate_pbar(p_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74dec0f8-e7d2-43eb-8005-079d4f0e423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the smoothed, scaled elongation rate lambda bar \n",
    "def calculate_lbar(pbar_list):\n",
    "    lbar_list=[]\n",
    "    for pbar in pbar_list:\n",
    "        lbar = []\n",
    "        for pbarx in pbar:\n",
    "            if pbarx == 0:\n",
    "                lbar_x=9999\n",
    "            else:\n",
    "                lbar_x = (1-9*pbarx)/(pbarx*(1-pbarx))\n",
    "            lbar.append(lbar_x)\n",
    "        lbar_list.append(np.array(lbar))\n",
    "    return(lbar_list)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf2d5f49-df63-47c3-b4fb-3a1787f38c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbar_list=calculate_lbar(pbar_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00b4f9c6-203a-419e-8d4b-ea2cb47513d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the scaled initiation and termination rates\n",
    "\n",
    "init_r= []\n",
    "for pbar in pbar_list:\n",
    "    if pbar[0] == 0:\n",
    "        init_r.append(1/(1-10*0.00001))\n",
    "    else:\n",
    "        init_r.append(1/(1-10*pbar[0]))\n",
    "\n",
    "term_r = []\n",
    "for p in p_list:\n",
    "    if p[-1] ==0:\n",
    "        term_r.append(1/0.00001)\n",
    "    else:\n",
    "        term_r.append(1/(p[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e4337df-d5fb-4a8d-9792-8bcb9c700642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deconvolve the smooth scaled elongation rates to calculate \n",
    "# the scaled codon specific elongation rates\n",
    "def calculate_tau (lbar_list,p_list,L=1):\n",
    "    tau_list = []\n",
    "    for Lam,p in zip(lbar_list,p_list):\n",
    "        b = 10*Lam\n",
    "        A = np.zeros((len(Lam),len(p)))\n",
    "        x=0\n",
    "        for row in A:\n",
    "            row[x:x+10].fill(1)\n",
    "            x = x+1\n",
    "        if L != 1:\n",
    "            b = b[L-1:]\n",
    "            A = A[L-1:] # Must double check that this is proper for A. \n",
    "        \n",
    "        test=lsqr(A,b)\n",
    "        Ci = test[0]\n",
    "        tau = Ci.mean()\n",
    "        tau_list.append(tau)\n",
    "    return(tau_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "87be3abc-62bf-4a47-a283-4aa5b40b6127",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_list=calculate_tau(lbar_list,p_list,L=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "11174783-aeb3-4b8d-8515-611ea6e00455",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_r = 1/tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "10135899-7d81-4dee-9ea2-ecbbe703061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the unscaled rates\n",
    "elongation = lbar_list[0]/tau_list[0]\n",
    "termination = term_r[0]\n",
    "initiation = init_r[0]/tau_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "409361d3-990b-468c-960c-fb4244cb8bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016669853627482297"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "dc69f87d-cc6f-413d-b71f-ccbf68e1e4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(save_path + 'keeg_gene_test.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(np.atleast_2d(elongation).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf51e7ce-b642-4722-8915-78937c661833",
   "metadata": {},
   "source": [
    "How it egg tart calculating the initiation and termination rates? at the moment it produces numbers totally different from what I calculated. Am I supposed to enter in what I calculated? Am I supposed to attach these to the start and end of the elongation file?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d548ec-0e4d-419b-85da-4186a6e34034",
   "metadata": {},
   "source": [
    "# Brought together into a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7b5d911a-17b2-4b07-91a9-0499ddba534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_rates(data, L = 1):\n",
    "    elongation_list = []\n",
    "    termination_list = []\n",
    "    initiation_list = []\n",
    "\n",
    "    for i in data:\n",
    "        # obtain a normalized profile (p) of ribosome footprints.\n",
    "        M = sum(i)\n",
    "        p = i/M \n",
    "    \n",
    "        # Calculate the smoothed density vector pbar for xth entry with length n-9\n",
    "        x=0\n",
    "        pbar=[]\n",
    "        for px in p:\n",
    "            pbar_x = 0.1*sum(p[x:x+10]) #it is x+10 not x+9 because python does not include the final index.\n",
    "            pbar.append(pbar_x)\n",
    "            x = x+1\n",
    "            if x  == len(p)-9:\n",
    "                break\n",
    "        pbar = np.array(pbar)\n",
    "        \n",
    "        # calculate the smoothed, scaled elongation rate lambda bar \n",
    "        lbar = []\n",
    "        for pbarx in pbar:\n",
    "            if pbarx == 0:\n",
    "                lbar_x=9999\n",
    "            else:\n",
    "                lbar_x = (1-9*pbarx)/(pbarx*(1-pbarx))\n",
    "\n",
    "            lbar.append(lbar_x)\n",
    "        lbar = np.array(lbar)\n",
    "        \n",
    "        # Calculate the scaled elongation and initiation rates\n",
    "        if pbar[0] == 0:\n",
    "            sc_init = 1/(1-10*0.00001)\n",
    "        else:\n",
    "            sc_init = 1/(1-10*pbar[0])\n",
    "        if p[-1] ==0:\n",
    "            sc_term = 1/0.00001\n",
    "        else:\n",
    "            sc_term = 1/(p[-1])\n",
    "            \n",
    "    # deconvolve the smooth scaled elongation rates to calculate \n",
    "    # the scaled codon specific elongation rates\n",
    "        b = 10*lbar\n",
    "        A = np.zeros((len(lbar),len(p)))\n",
    "        x=0\n",
    "        for row in A:\n",
    "            row[x:x+10].fill(1)\n",
    "            x = x+1\n",
    "        if L != 1:\n",
    "            b = b[L-1:]\n",
    "            A = A[L-1:] # Must double check that this is proper for A. \n",
    "        \n",
    "        test=lsqr(A,b)\n",
    "        Ci = test[0]\n",
    "        tau = Ci.mean()\n",
    "        \n",
    "        elongation = lbar/tau\n",
    "        termination = sc_term # This makes no sense, it always ends up being huge... maybe it is just len(p)/M?\n",
    "        initiation = sc_init/tau\n",
    "        \n",
    "        elongation_list.append(elongation)\n",
    "        termination_list.append(termination)\n",
    "        initiation_list.append(initiation)\n",
    "    return(elongation_list,termination_list,initiation_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "29a722e7-47e8-4668-97c9-df37d39739aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "el,tl,il = determine_rates(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3360688f-b7d9-4495-990b-3cfb08391bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.016669853627482297, 0.01865871865832989, 0.029289236953547824]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e798c08-3664-45a4-95ff-10090272cb98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
