{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12dbf983-0403-4298-97f6-8d9fef7130ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Count Arrays for Sharma et al. 2019\n",
    "\n",
    "This notebook is a short pipeline that creates a list of count vectors that show the number of reads recorded for each gene at each codon position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd73df04-2aa8-4ee1-bdf5-e016d8347975",
   "metadata": {},
   "source": [
    "### Step 1:\n",
    "Activate the Plastid conda environment and open up a Jupyter Lab session (alternatively, a python file can be run in this conda environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a24f68-a2f3-4fde-9abd-9797a42b8939",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 2: \n",
    "Load in all of the necessary packages from Plastid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffbf70ed-d84e-424a-9cd1-33b185761325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let the program know where to find your tools file.\n",
    "import sys\n",
    "sys.path.append('/home/keeganfl/Desktop/Work_Fall_2021/Fall_2021_Work_journal/tools/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9acbc26a-6e33-4bc1-acd1-3142afdd74cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "from plastid import BAMGenomeArray, VariableFivePrimeMapFactory, \\\n",
    "                        GTF2_TranscriptAssembler, GFF3_TranscriptAssembler, \\\n",
    "                        Transcript, ThreePrimeMapFactory\n",
    "import numpy as np\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "import numpy\n",
    "import math\n",
    "import pandas as pd\n",
    "from plastid.plotting.plots import *\n",
    "from scipy import stats\n",
    "from scipy.stats import kstwo\n",
    "import keegan_analysis_tools as kat\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline\n",
    "import csv\n",
    "from scipy.sparse.linalg import lsqr\n",
    "from tqdm import tqdm\n",
    "from multiprocess import Pool\n",
    "import copy\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "683cb4e9-859b-421a-b432-e592c088a064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to important files\n",
    "data_path = \"/home/keeganfl/Desktop/Work_Fall_2021/genomes_&_samples/mmus/\"\n",
    "save_path = \"/home/keeganfl/Desktop/Work_Fall_2021/data_tables/position_counts_codon_resolution/mmus/\"\n",
    "p_site_path = \"/home/keeganfl/Desktop/Work_Fall_2021/data_tables/p-site_offsets/mmus/\"\n",
    "mutation = 'control'\n",
    "samp_num = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe402387-45c8-4b1c-9e25-4bcd1cd76043",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3\n",
    "Load in your P-site offset files using the \\verb|read_csv()| function from pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b02aa05b-ae67-4f35-9f6f-122833357769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the table of P-site offsets. \n",
    "p_offsets=pd.read_csv(p_site_path + mutation + \"_RPF_\" + samp_num + \"_Aligned.toTranscriptome.out_p-site-offsets\", \n",
    "                      sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2917ba-2038-47b9-a7db-c002162fd659",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "Load in a GTF genome annotation file into python using Plastid's GTF2_TranscriptAssembler() function. This function will load in the transcripts as an iterator of transcript type objects which we will convert to a list. In most cases, we will then want to filter this list so that only the protein coding genes transcripts are present. In the event that only protein coding genes are present in the GTF file this step should be skipped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6602aae6-6ecf-4e5f-b146-24a11b3409fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the transcript annotations from the GTF file.\n",
    "# GTF2_TranscriptAssembler returns an iterator, so here we convert it to a list.\n",
    "transcripts = list(GTF2_TranscriptAssembler(open(data_path + \"mm10.refGene.gtf\"),return_type=Transcript))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f2ba2d-61cd-424a-8b81-4d56a877e693",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 5\n",
    "item Load in the Bam file containing the Ribosome Profiling data as a Bam Genome Array using Plastid's BamGenomeArray() function. While loading in these bam files, map the read alignments to their corresponding P-sites. Plastid does not have a pre-built function that can assign P-site offsets from the 3' end for varying read lengths. Therefore, In order to apply the per read length P-site offsets we calculated using riboWaltz, it is necessary to create our own python function called \\verb|VariableThreePrimeMapFactory| based on the inner workings of the VariableFivePrimeMapFactory function that comes prepackaged with Plastid. You can find an example of this function in the keegan_analysis_tools.py file on the GitHub page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec43099-d578-40bc-8286-3a59cabc59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the alignments from a BAM file and then have it map to the p-site \n",
    "alignments = BAMGenomeArray(data_path + mutation + \"_RPF_\" + samp_num + \"_Aligned.sortedByCoord.out.bam\")\n",
    "alignments.set_mapping(kat.VariableThreePrimeMapFactory(p_offsets=p_offsets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9381f867-d629-4b6e-b470-b2a40536a1c6",
   "metadata": {},
   "source": [
    "### Step 6\n",
    "For each \\verb|transcript| object in our list we are going to use plastids \\verb|get_counts()| method to to create a numpy array that contains the number of counts at each position in the transcript. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc2d803-79d3-4707-a53b-e9db9df0d601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a list to hold the vectors\n",
    "count_vectors = []\n",
    "\n",
    "# get counts for each transcript\n",
    "for transcript in transcripts:\n",
    "    count_vectors.append(transcript.get_counts(alignments))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb68fd8-a6b9-4462-95c2-1f1542322f00",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 7\n",
    "Once we have created our count arrays we are going to want to convert them from nucleotide resolution to codon resolution for some of the modelling we are going to do later. This can be done easily by calculating the sum of the counts every three positions using numpy's \\verb|add.reduceat()| function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73285e0f-8590-4c03-b9d0-531ed13a24c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the loacation of the start and end of the coding region for each transcript. \n",
    "cds_starts = []\n",
    "cds_ends = []\n",
    "\n",
    "for transcript in transcripts:\n",
    "    cds_starts.append(transcript.cds_start)\n",
    "    cds_ends.append(transcript.cds_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21885a3f-487a-4ee1-9002-2e5b9094f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of lists containing the counts at each position of the transcript cds regions.\n",
    "cds_counts_list = []\n",
    "\n",
    "for i in range(len(count_vectors)):\n",
    "    x = list(count_vectors[i][cds_starts[i]:cds_ends[i]])\n",
    "    cds_counts_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca2150d-ad66-483b-8bdf-63183d05d126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the count lists from nucleotide resolution to codon resolution\n",
    "codon_counts = []\n",
    "\n",
    "for i in cds_counts_list:\n",
    "    codon_counts.append(np.add.reduceat(i, np.arange(0, len(i),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac55ae7-f5c8-4591-81f5-04b7f0e6e0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the unscaled elongation rates to a list so they can be more easily saved\n",
    "for count, i in zip(codon_counts, list(range(len(codon_counts)))):\n",
    "    codon_counts[i] = count.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7563712b-2f52-4efd-adeb-f70331199a7f",
   "metadata": {},
   "source": [
    "### Step 8\n",
    "save the count arrays to be used in future notebooks. You may find it helpful to use the save_count_positions() function from keegan_analysis_tools.py so that the count arrays are saved with their gene name and transcript ids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c228df8d-640d-492a-b78f-7ce2fb7a352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kat.save_count_positions(transcripts, codon_counts, save_path, mutation + \"_\" + samp_num + '_counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398c54e6-e7bd-48fc-bbe5-118dc870455a",
   "metadata": {},
   "source": [
    "## Analyzing the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c807ff31-89f3-4d69-ae96-05d38896549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the transcript and vector for the gene of interest\n",
    "my_transcript, my_vector = kat.find_tran_mmus('Syn1', transcripts, count_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dfcf6f-1e02-4048-8f7f-30a182180ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30-codon sliding window average\n",
    "window = np.ones(90).astype(float)/90.0\n",
    "sliding_window_avg = np.convolve(my_vector,window,mode=\"valid\")\n",
    "\n",
    "\n",
    "# plot\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(my_vector,label=\"%s counts\" % my_transcript.get_name())\n",
    "plt.plot(sliding_window_avg,label=\"30 codon average\")\n",
    "plt.xlabel(\"Position in transcript (5' to 3')\")\n",
    "plt.ylabel(\"Ribosome counts\")\n",
    "\n",
    "# add outlines at start & stop codons\n",
    "plt.axvline(my_transcript.cds_start,color=\"#999999\",dashes=[3,2],zorder=-1)\n",
    "plt.axvline(my_transcript.cds_end,color=\"#999999\",dashes=[3,2],zorder=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac728d91-b597-472e-b509-7e3b065986ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
