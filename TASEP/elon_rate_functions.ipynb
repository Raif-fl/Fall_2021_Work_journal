{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b1a7d4-8ede-4530-8784-598021ff19b7",
   "metadata": {},
   "source": [
    "## Loading up packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceab2473-7d5f-44ca-9727-b10ab5a27f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plastid\n",
    "# data structure for mapping read alignments to genomic positions\n",
    "from plastid import BAMGenomeArray, VariableFivePrimeMapFactory, \\\n",
    "                        GTF2_TranscriptAssembler, Transcript, ThreePrimeMapFactory\n",
    "import numpy as np\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import csv\n",
    "from scipy.sparse.linalg import lsqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1e784bd-8656-4bd0-9be6-27ef04ece771",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/Users/keeganflanagan/Desktop/Khanh_position/Eggtart/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3964f9cb-c183-4a98-ab01-37334ceeade8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading up the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5837a43c-99f0-4fe2-9727-4c805131f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data row by row.\n",
    "data = []\n",
    "with open(\"toy_data.csv\", newline = '') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8acb5dbd-396b-4d6e-888b-48998f6dc6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pop out the header row.\n",
    "blank=data.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40668469-516e-4544-8de2-2f1913e1fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert everything to an integer if possible. \n",
    "for i,ii in zip(data, range(len(data))):\n",
    "    for j,jj in zip(i, range(len(i))):\n",
    "        try:\n",
    "            x = int(j)\n",
    "            data[ii][jj] = x\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f798c4ba-25a8-4c14-a0d5-ada794ffd463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty space\n",
    "for i,ii in zip(data, range(len(data))):\n",
    "    x = list(filter(('').__ne__, i))\n",
    "    data[ii] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8379e568-7689-4314-82c9-63c480c67525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert lists to np.arrays\n",
    "for i,ii in zip(data, range(len(data))):\n",
    "    data[ii] = np.array(data[ii][2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfad7b5-b80b-4b95-b24e-a4d36ebd44b0",
   "metadata": {},
   "source": [
    "## Perform the calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c751070-c12f-4445-a93a-72a22cc9065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to obtain a normalized profile (p) of ribosome footprints.\n",
    "def calculate_p(data):\n",
    "    p_list=[]\n",
    "    for i in data:\n",
    "        M = sum(i)\n",
    "        p = i/M\n",
    "        p_list.append(p)\n",
    "    return(p_list)\n",
    "\n",
    "# Note that I am assuming here that by number of transcripts they meant number of reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "258b7055-d8b0-4e6a-bbb7-4b4c12070b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list = calculate_p(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17231693-a385-4ea1-9f76-20a8cf48f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the smoothed density vector pbar for xth entry with length n-9\n",
    "def calculate_pbar(p_list):\n",
    "    pbar_list=[]\n",
    "    for p in p_list:\n",
    "        x=0\n",
    "        pbar=[]\n",
    "        for px in p:\n",
    "            pbar_x = 0.1*sum(p[x:x+10]) #it is x+10 not x+9 because python does not include the final index.\n",
    "            pbar.append(pbar_x)\n",
    "            x = x+1\n",
    "            if x  == len(p)-9:\n",
    "                break\n",
    "        pbar_list.append(np.array(pbar))\n",
    "    return(pbar_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f382947-dd33-45fa-9ad2-0ded3d095c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar_list=calculate_pbar(p_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74dec0f8-e7d2-43eb-8005-079d4f0e423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the smoothed, scaled elongation rate lambda bar \n",
    "def calculate_lbar(pbar_list):\n",
    "    lbar_list=[]\n",
    "    for pbar in pbar_list:\n",
    "        lbar = []\n",
    "        for pbarx in pbar:\n",
    "            if pbarx == 0:\n",
    "                lbar_x=9999\n",
    "            else:\n",
    "                lbar_x = (1-9*pbarx)/(pbarx*(1-pbarx))\n",
    "            lbar.append(lbar_x)\n",
    "        lbar_list.append(np.array(lbar))\n",
    "    return(lbar_list)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf2d5f49-df63-47c3-b4fb-3a1787f38c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbar_list=calculate_lbar(pbar_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00b4f9c6-203a-419e-8d4b-ea2cb47513d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the scaled initiation and termination rates\n",
    "\n",
    "init_r= []\n",
    "for pbar in pbar_list:\n",
    "    if pbar[0] == 0:\n",
    "        init_r.append(1/(1-10*0.00001))\n",
    "    else:\n",
    "        init_r.append(1/(1-10*pbar[0]))\n",
    "\n",
    "term_r = []\n",
    "for p in p_list:\n",
    "    if p[-1] ==0:\n",
    "        term_r.append(1/0.00001)\n",
    "    else:\n",
    "        term_r.append(1/(p[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e4337df-d5fb-4a8d-9792-8bcb9c700642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deconvolve the smooth scaled elongation rates to calculate \n",
    "# the scaled codon specific elongation rates\n",
    "def calculate_tau (lbar_list,p_list,L=1):\n",
    "    tau_list = []\n",
    "    for Lam,p in zip(lbar_list,p_list):\n",
    "        b = 10*Lam\n",
    "        A = np.zeros((len(Lam),len(p)))\n",
    "        x=0\n",
    "        for row in A:\n",
    "            row[x:x+10].fill(1)\n",
    "            x = x+1\n",
    "        if L != 1:\n",
    "            b = b[L-1:]\n",
    "            A = A[L-1:] # Must double check that this is proper for A. \n",
    "        \n",
    "        test=lsqr(A,b)\n",
    "        Ci = test[0]\n",
    "        tau = Ci.mean()\n",
    "        tau_list.append(tau)\n",
    "    return(tau_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87be3abc-62bf-4a47-a283-4aa5b40b6127",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_list=calculate_tau(lbar_list,p_list,L=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11174783-aeb3-4b8d-8515-611ea6e00455",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tau' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qb/9w2nd7954vj2jt5sb31w7g_80000gn/T/ipykernel_34699/3895040768.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprod_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tau' is not defined"
     ]
    }
   ],
   "source": [
    "prod_r = 1/tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "10135899-7d81-4dee-9ea2-ecbbe703061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the unscaled rates\n",
    "elongation = lbar_list[0]/tau_list[0]\n",
    "termination = term_r[0]\n",
    "initiation = init_r[0]/tau_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "409361d3-990b-468c-960c-fb4244cb8bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016669853627482297"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "dc69f87d-cc6f-413d-b71f-ccbf68e1e4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path + 'keeg_gene_test.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(np.atleast_2d(elongation).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf51e7ce-b642-4722-8915-78937c661833",
   "metadata": {},
   "source": [
    "How it egg tart calculating the initiation and termination rates? at the moment it produces numbers totally different from what I calculated. Am I supposed to enter in what I calculated? Am I supposed to attach these to the start and end of the elongation file?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d548ec-0e4d-419b-85da-4186a6e34034",
   "metadata": {},
   "source": [
    "# Brought together into a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7b5d911a-17b2-4b07-91a9-0499ddba534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_rates(data, L = 1):\n",
    "    elongation_list = []\n",
    "    termination_list = []\n",
    "    initiation_list = []\n",
    "\n",
    "    for i in data:\n",
    "        # obtain a normalized profile (p) of ribosome footprints.\n",
    "        M = sum(i)\n",
    "        p = i/M \n",
    "    \n",
    "        # Calculate the smoothed density vector pbar for xth entry with length n-9\n",
    "        x=0\n",
    "        pbar=[]\n",
    "        for px in p:\n",
    "            pbar_x = 0.1*sum(p[x:x+10]) #it is x+10 not x+9 because python does not include the final index.\n",
    "            pbar.append(pbar_x)\n",
    "            x = x+1\n",
    "            if x  == len(p)-9:\n",
    "                break\n",
    "        pbar = np.array(pbar)\n",
    "        \n",
    "        # calculate the smoothed, scaled elongation rate lambda bar \n",
    "        lbar = []\n",
    "        for pbarx in pbar:\n",
    "            if pbarx == 0:\n",
    "                lbar_x=9999\n",
    "            else:\n",
    "                lbar_x = (1-9*pbarx)/(pbarx*(1-pbarx))\n",
    "\n",
    "            lbar.append(lbar_x)\n",
    "        lbar = np.array(lbar)\n",
    "        \n",
    "        # Calculate the scaled elongation and initiation rates\n",
    "        if pbar[0] == 0:\n",
    "            sc_init = 1/(1-10*0.00001)\n",
    "        else:\n",
    "            sc_init = 1/(1-10*pbar[0])\n",
    "        if p[-1] ==0:\n",
    "            sc_term = 1/0.00001\n",
    "        else:\n",
    "            sc_term = 1/(p[-1])\n",
    "            \n",
    "    # deconvolve the smooth scaled elongation rates to calculate \n",
    "    # the scaled codon specific elongation rates\n",
    "        b = 10*lbar\n",
    "        A = np.zeros((len(lbar),len(p)))\n",
    "        x=0\n",
    "        for row in A:\n",
    "            row[x:x+10].fill(1)\n",
    "            x = x+1\n",
    "        if L != 1:\n",
    "            b = b[L-1:]\n",
    "            A = A[L-1:] # Must double check that this is proper for A. \n",
    "        \n",
    "        test=lsqr(A,b)\n",
    "        Ci = test[0]\n",
    "        tau = Ci.mean()\n",
    "        \n",
    "        elongation = lbar/tau\n",
    "        termination = sc_term # This makes no sense, it always ends up being huge... maybe it is just len(p)/M?\n",
    "        initiation = sc_init/tau\n",
    "        \n",
    "        elongation_list.append(elongation)\n",
    "        termination_list.append(termination)\n",
    "        initiation_list.append(initiation)\n",
    "    return(elongation_list,termination_list,initiation_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "29a722e7-47e8-4668-97c9-df37d39739aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "el,tl,il = determine_rates(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3360688f-b7d9-4495-990b-3cfb08391bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.016669853627482297, 0.01865871865832989, 0.029289236953547824]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e798c08-3664-45a4-95ff-10090272cb98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
