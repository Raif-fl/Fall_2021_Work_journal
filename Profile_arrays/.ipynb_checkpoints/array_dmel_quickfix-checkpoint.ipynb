{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12dbf983-0403-4298-97f6-8d9fef7130ac",
   "metadata": {},
   "source": [
    "# Count Arrays for Greenblatt and Spradling D. Melanogaster data\n",
    "\n",
    "This notebook contains a variety of code that allows me to create arrays of counts at each transcript position (nucleotide precision). \n",
    "\n",
    "Note that depending on the number of samples you are using, this notebook may use up a large amount of RAM (about 2-4 GB per sample). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0c3c45-529f-44f5-b0b8-790f72cc2825",
   "metadata": {},
   "source": [
    "## loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef4ccd24-5ff1-481e-b87e-f68fe4f83a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plastid\n",
    "# data structure for mapping read alignments to genomic positions\n",
    "from plastid import BAMGenomeArray, VariableFivePrimeMapFactory, \\\n",
    "                        GTF2_TranscriptAssembler, Transcript, ThreePrimeMapFactory\n",
    "import numpy as np\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import csv\n",
    "from scipy.sparse.linalg import lsqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8de37de6-d737-4af2-af06-1fdf6e2f8545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to our Bam files\n",
    "data_path = \"/home/keeganfl/Desktop/Work_Fall_2021/genomes_&_samples/dmel/\"\n",
    "save_path = \"/home/keeganfl/Desktop/Work_Fall_2021/data_tables/position_counts/dmel/\"\n",
    "p_site_path = \"/home/keeganfl/Desktop/Work_Fall_2021/data_tables/p-site_offsets/dmel/\"\n",
    "sample_name = 'Fmr1_RPF_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5f7a9f-d22e-4ba1-b844-f83838f46b84",
   "metadata": {},
   "source": [
    "## Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d21a096c-e5fa-47af-8858-cb53ab081e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_threeprime_map_function(alignments,segment,p_offsets):\n",
    "        '''\n",
    "        This function is used to map read alignments to the location of the ribosomal p-site \n",
    "        from their 3' end. The offsets to use for each read length are specified by file\n",
    "        generated using RiboWaltz.\n",
    "\n",
    "        alignments:\n",
    "            Information on the genome alignment of an individual read which is passed \n",
    "            to the function from a BamGenome array created by plastid. \n",
    "\n",
    "        segment:\n",
    "            Information on the individual read segment which is passed \n",
    "            to the function from a BamGenome array created by plastid. \n",
    "\n",
    "        p_offsets:\n",
    "            A pandas dataframe that has been loaded into the python environmemt.\n",
    "            This dataframe should follow this template. \n",
    "                length          P_offsets\n",
    "                 28              12\n",
    "                 29              12\n",
    "                 30              13\n",
    "                ...             ...\n",
    "\n",
    "        '''\n",
    "        reads_out = []\n",
    "        count_array = numpy.zeros(len(segment))\n",
    "        for read in alignments: \n",
    "            for length, offset in zip(p_offsets[\"length\"],p_offsets[\"p_offset\"]): \n",
    "                if length != len(read.positions):\n",
    "                    continue # skip read if it is not the length we are currently offsetting.\n",
    "\n",
    "             # count offset 3' to 5' if the `segment` is on the plus-strand\n",
    "             # or is unstranded\n",
    "                if segment.strand == \"+\":\n",
    "                    p_site = read.positions[-offset - 1]\n",
    "                elif segment.strand == \".\":\n",
    "                    p_site = read.positions[-offset - 1]\n",
    "             # count offset from other end if `segment` is on the minus-strand\n",
    "                elif segment.strand == \"-\":\n",
    "                    p_site = read.positions[offset]\n",
    "\n",
    "                if p_site >= segment.start and p_site < segment.end:\n",
    "                    reads_out.append(read)\n",
    "                    count_array[p_site - segment.start] += 1\n",
    "        return reads_out, count_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e81dc03-6a6e-4238-b14d-4169d1740a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VariableThreePrimeMapFactory(p_offsets):\n",
    "    '''\n",
    "    BamGenome array objects will only be able to pass the alignments and segment\n",
    "    arguments to the variable_threeprime_map_function. This wrapper allows me to\n",
    "    also specify the offset that needs to be passed to the function. \n",
    "    '''\n",
    "    def new_func(alignments,segment):\n",
    "        return variable_threeprime_map_function(alignments,segment,p_offsets=p_offsets)\n",
    "\n",
    "    return new_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "759a57b3-3a15-4956-a62c-1996c72e1d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that finds the proteins I need. \n",
    "def find_transcript(gene,transcripts, count_vectors):\n",
    "    '''\n",
    "    A function that takes the name of a gene as input and finds \n",
    "    the corresponding transcript from a transcript list. \n",
    "    \n",
    "    returns both the transcript in question and the vector of counts for that transcript.\n",
    "    \n",
    "    This function is still a work in progress as for now it simply gives the last \n",
    "    transcript in the list that matches the gene ID. \n",
    "    '''\n",
    "    for i in transcripts:\n",
    "        if i.attr['transcript_biotype'] == 'protein_coding':\n",
    "            if i.attr['gene_name'] == gene:\n",
    "                my_transcript = i\n",
    "                my_vector = count_vectors[transcripts.index(i)]\n",
    "                print(transcripts.index(i))\n",
    "                \n",
    "    return my_transcript, my_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1234976c-60b5-4bc3-8df1-e8f62ee16d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_list(list):\n",
    "    ''' \n",
    "    A function that finds the longest list/array in a list of lists. \n",
    "    '''\n",
    "    list_len = [len(i) for i in list]\n",
    "    return(max(list_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d83bd9b-3686-4901-92e1-8895346a8b32",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading up the data files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b02aa05b-ae67-4f35-9f6f-122833357769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the table of P-site offsets. \n",
    "p_offsets=pd.read_csv(p_site_path + sample_name + \"_Aligned.toTranscriptome.out_p-site-offsets\", \n",
    "                      sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6602aae6-6ecf-4e5f-b146-24a11b3409fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the transcript annotations from the GTF file.\n",
    "# GTF2_TranscriptAssembler returns an iterator, so here we convert it to a list.\n",
    "transcripts = list(GTF2_TranscriptAssembler(open(data_path + \"Drosophila_melanogaster.BDGP6.32.103.gtf\"),return_type=Transcript))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be097b2-2a7c-4b81-a9b4-828cab2dbad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-protein coding transcripts from transcripts list. \n",
    "protein_coding = []\n",
    "for transcript in transcripts:\n",
    "    if transcript.attr['transcript_biotype'] == 'protein_coding':\n",
    "        protein_coding.append(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb6aa27-2b50-47e5-8536-c69e82c64d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear up some memory by deleting original transcript list\n",
    "transcripts.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec43099-d578-40bc-8286-3a59cabc59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the alignments from a BAM file and then have it map to the p-site \n",
    "alignments = BAMGenomeArray(data_path + sample_name + \"_Aligned.sortedByCoord.out.bam\")\n",
    "alignments.set_mapping(VariableThreePrimeMapFactory(p_offsets=p_offsets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc2d803-79d3-4707-a53b-e9db9df0d601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a list to hold the vectors\n",
    "count_vectors_control = []\n",
    "\n",
    "# get counts for each transcript\n",
    "for transcript in protein_coding:\n",
    "    count_vectors_control.append(transcript.get_counts(alignments))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c393c56c-c0c4-4f5f-bc6b-b0ffa663fa2d",
   "metadata": {},
   "source": [
    "The function below takes a gene name as input and finds the correct transcript and vector for that gene. Note that this function is specifically made to work with the Drosophila_melanogaster.BDGP6.32.103.gtf file used to create the transcripts in this notebook. If you create the transcripts using a different file this function will need to be altered. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db4a888-8e6a-4bc1-8554-542c887aae9c",
   "metadata": {},
   "source": [
    "## Analyzing the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1fd565-4baf-4429-9e21-d288ae1882d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the transcript and vector for the gene of interest\n",
    "my_transcript, my_vector_control = find_transcript('lost', protein_coding, count_vectors_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4904ac-040d-4d01-b051-349b1171425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30-codon sliding window average\n",
    "window = np.ones(90).astype(float)/90.0\n",
    "sliding_window_avg = np.convolve(my_vector_control,window,mode=\"valid\")\n",
    "\n",
    "\n",
    "# plot\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(my_vector_control,label=\"%s counts\" % my_transcript.get_name())\n",
    "plt.plot(sliding_window_avg,label=\"30 codon average\")\n",
    "plt.xlabel(\"Position in transcript (5' to 3')\")\n",
    "plt.ylabel(\"Ribosome counts\")\n",
    "\n",
    "# add outlines at start & stop codons\n",
    "plt.axvline(my_transcript.cds_start,color=\"#999999\",dashes=[3,2],zorder=-1)\n",
    "plt.axvline(my_transcript.cds_end,color=\"#999999\",dashes=[3,2],zorder=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdcbc69-2124-4ed9-a0f4-6c4c68232779",
   "metadata": {},
   "source": [
    "transcript position 1230 to 1233 corresponds to the pause site for Xbp1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11093c8-e9bb-4bfd-bb97-8c7dfafc602e",
   "metadata": {},
   "source": [
    "## Alter the count vectors to look at the codons over the cds region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4539e74d-129f-462e-bd2b-35bd514e51a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list that contains all of the gene_ids and transcript_ids of the transcripts\n",
    "gene_id = []\n",
    "transcript_id = []\n",
    "\n",
    "for transcript in protein_coding:\n",
    "    gene_id.append(transcript.attr[\"gene_name\"])\n",
    "    transcript_id.append(transcript.attr[\"transcript_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73285e0f-8590-4c03-b9d0-531ed13a24c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the loacation of the start and end of the coding region for each transcript. \n",
    "cds_starts = []\n",
    "cds_ends = []\n",
    "\n",
    "for transcript in protein_coding:\n",
    "    cds_starts.append(transcript.cds_start)\n",
    "    cds_ends.append(transcript.cds_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21885a3f-487a-4ee1-9002-2e5b9094f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of lists containing the counts at each position of the transcript cds regions.\n",
    "cds_counts_list = []\n",
    "\n",
    "for i in range(len(count_vectors_control)):\n",
    "    x = list(count_vectors_control[i][cds_starts[i]:cds_ends[i]])\n",
    "    cds_counts_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca2150d-ad66-483b-8bdf-63183d05d126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the count lists from nucleotide resolution to codon resolution\n",
    "codon_counts = []\n",
    "\n",
    "for i in cds_counts_list:\n",
    "    codon_counts.append(np.add.reduceat(i, np.arange(0, len(i),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dea320-b6dd-41b7-a982-a7efb49a92e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257f0df5-9ef7-4523-801e-bcca61c8214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list that contains all of the gene_ids and transcript_ids of the transcripts\n",
    "gene_id = []\n",
    "transcript_id = []\n",
    "\n",
    "for transcript in protein_coding:\n",
    "    gene_id.append(transcript.attr[\"gene_name\"])\n",
    "    transcript_id.append(transcript.attr[\"transcript_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a4462-e3cf-43fc-a1dd-073364addd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the gene ids and transcript ids into the codon_count list. \n",
    "for i, j in zip(codon_counts, range(len(gene_id))):\n",
    "    i.insert(0,gene_id[j])\n",
    "    i.insert(0,transcript_id[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64041873-940f-40d8-84f4-da6dc2961d74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the longest cds region in our new list of counts\n",
    "l_tr = find_max_list(codon_counts)\n",
    "\n",
    "# Define a header that includes labels for the transcript and gene ID as \n",
    "# well as numbers that index the cds region position.\n",
    "header=[\"transcript_id\",\"gene_id\"]+list(range(l_tr))\n",
    "\n",
    "# insert that header into our counts list. \n",
    "codon_counts.insert(0,header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326251d4-8f92-4bef-8e4b-e3a00a07a53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path + sample_name + '_counts.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(codon_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c39a68a-2db5-4831-9fb7-2eaa57ccf2a1",
   "metadata": {},
   "source": [
    "Do you think there is such thing as an average count array? I am just trying to figure out how we work multiple samples into this kind of analyses smoothly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819c7f20-664e-485e-a269-59cb86317860",
   "metadata": {},
   "source": [
    "Doing just the coding region should be as easy as indexing each transcript from my_count_vectors with the numbers you get from transcript.cds_start and transcript.cds_end\n",
    "\n",
    "Hmmm, Perhaps I should keep the transcript position for the index rather than use the coding region position for the index? I mean it would be easy enough to fix but it is still kind of annoying. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179a6876-2b9c-4adc-b6a1-9f169526d80e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
